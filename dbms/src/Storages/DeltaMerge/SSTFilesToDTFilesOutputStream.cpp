#include <Common/ProfileEvents.h>
#include <Common/TiFlashMetrics.h>
#include <Interpreters/Context.h>
#include <Poco/File.h>
#include <RaftStoreProxyFFI/ColumnFamily.h>
#include <Storages/DeltaMerge/DeltaMergeStore.h>
#include <Storages/DeltaMerge/File/DMFile.h>
#include <Storages/DeltaMerge/File/DMFileBlockOutputStream.h>
#include <Storages/DeltaMerge/SSTFilesToDTFilesOutputStream.h>
#include <Storages/StorageDeltaMerge.h>
#include <Storages/Transaction/PartitionStreams.h>
#include <Storages/Transaction/ProxyFFI.h>
#include <Storages/Transaction/Region.h>
#include <Storages/Transaction/SSTReader.h>
#include <Storages/Transaction/TMTContext.h>
#include <common/logger_useful.h>

namespace ProfileEvents
{
extern const Event DMWriteBytes;
}

namespace DB
{

namespace ErrorCodes
{
extern const int ILLFORMAT_RAFT_ROW;
} // namespace ErrorCodes

namespace DM
{

SSTFilesToDTFilesOutputStream::SSTFilesToDTFilesOutputStream( //
    BoundedSSTFilesToBlockInputStreamPtr  child_,
    StorageDeltaMergePtr                  storage_,
    const DecodingStorageSchemaSnapshot & schema_snap_,
    TiDB::SnapshotApplyMethod             method_,
    FileConvertJobType                    job_type_,
    TMTContext &                          tmt_)
    : child(std::move(child_)), //
      storage(std::move(storage_)),
      schema_snap(schema_snap_),
      method(method_),
      job_type(job_type_),
      tmt(tmt_),
      log(&Poco::Logger::get("SSTFilesToDTFilesOutputStream"))
{
}

SSTFilesToDTFilesOutputStream::~SSTFilesToDTFilesOutputStream() = default;

void SSTFilesToDTFilesOutputStream::writePrefix()
{
    child->readPrefix();

    commit_rows = 0;
    watch.start();
}

void SSTFilesToDTFilesOutputStream::writeSuffix()
{
    child->readSuffix();

    if (dt_stream != nullptr)
    {
        dt_stream->writeSuffix();
        auto dt_file = dt_stream->getFile();
        assert(!dt_file->canGC()); // The DTFile should not be able to gc until it is ingested.
        // Add the DTFile to StoragePathPool so that we can restore it later
        const auto bytes_written = dt_file->getBytesOnDisk();
        storage->getStore()->preIngestFile(dt_file->parentPath(), dt_file->fileId(), bytes_written);

        // Report DMWriteBytes for calculating write amplification
        ProfileEvents::increment(ProfileEvents::DMWriteBytes, bytes_written);

        dt_stream.reset();
    }

    auto &     ctx          = tmt.getContext();
    auto       metrics      = ctx.getTiFlashMetrics();
    const auto process_keys = child->getProcessKeys();
    if (job_type == FileConvertJobType::ApplySnapshot)
    {
        GET_METRIC(metrics, tiflash_raft_command_duration_seconds, type_apply_snapshot_predecode).Observe(watch.elapsedSeconds());
        // Note that number of keys in different cf will be aggregated into one metrics
        GET_METRIC(metrics, tiflash_raft_process_keys, type_apply_snapshot).Increment(process_keys.total());
    }
    else
    {
        // Note that number of keys in different cf will be aggregated into one metrics
        GET_METRIC(metrics, tiflash_raft_process_keys, type_ingest_sst).Increment(process_keys.total());
    }
    LOG_INFO(log,
             "Pre-handle snapshot " << child->getRegion()->toString(true) << " to " << ingest_files.size() << " DTFiles, cost "
                                    << watch.elapsedMilliseconds() << "ms [rows=" << commit_rows
                                    << "] [write_cf_keys=" << process_keys.write_cf << "] [default_cf_keys=" << process_keys.default_cf
                                    << "] [lock_cf_keys=" << process_keys.lock_cf << "]");
}

bool SSTFilesToDTFilesOutputStream::newDTFileStream()
{
    // Generate a DMFilePtr and its DMFileBlockOutputStream
    DMFileBlockOutputStream::Flags flags;
    switch (method)
    {
    case TiDB::SnapshotApplyMethod::DTFile_Directory:
        flags.setSingleFile(false);
        break;
    case TiDB::SnapshotApplyMethod::DTFile_Single:
        flags.setSingleFile(true);
        break;
    default:
        break;
    }

    // The parent_path and file_id are generated by the storage.
    auto [parent_path, file_id] = storage->getStore()->preAllocateIngestFile();
    if (parent_path.empty())
    {
        // Can no allocate path and id for storing DTFiles (the storage may be dropped / shutdown)
        return false;
    }
    auto dt_file = DMFile::create(file_id, parent_path, flags.isSingleFile());
    LOG_INFO(log,
             "Create file for snapshot data " << child->getRegion()->toString(true) << " [file=" << dt_file->path()
                                              << "] [single_file_mode=" << flags.isSingleFile() << "]");
    dt_stream = std::make_unique<DMFileBlockOutputStream>(tmt.getContext(), dt_file, *(schema_snap.column_defines), flags);
    dt_stream->writePrefix();
    ingest_files.emplace_back(dt_file);
    return true;
}

void SSTFilesToDTFilesOutputStream::write()
{
    size_t last_effective_num_rows = 0;
    size_t last_not_clean_rows     = 0;
    size_t cur_effective_num_rows  = 0;
    size_t cur_not_clean_rows      = 0;
    while (true)
    {

        Block block = child->read();
        if (!block)
            break;
        if (unlikely(block.rows() == 0))
            continue;

        if (dt_stream == nullptr)
        {
            // If can not create DTFile stream (the storage may be dropped / shutdown),
            // break the writing loop.
            if (bool ok = newDTFileStream(); !ok)
            {
                break;
            }
        }

        {
            // Check whether rows are sorted by handle & version in ascending order.
            SortDescription sort;
            sort.emplace_back(MutableSupport::tidb_pk_column_name, 1, 0);
            sort.emplace_back(MutableSupport::version_column_name, 1, 0);
            if (unlikely(block.rows() > 1 && !isAlreadySorted(block, sort)))
            {
                const String error_msg
                    = "The block decoded from SSTFile is not sorted by primary key and version " + child->getRegion()->toString(true);
                LOG_ERROR(log, error_msg);
                FieldVisitorToString visitor;
                const size_t         nrows = block.rows();
                for (size_t i = 0; i < nrows; ++i)
                {
                    const auto & pk_col  = block.getByName(MutableSupport::tidb_pk_column_name);
                    const auto & ver_col = block.getByName(MutableSupport::version_column_name);
                    LOG_ERROR(log,
                              "[Row=" << i << "/" << nrows << "] [pk=" << applyVisitor(visitor, (*pk_col.column)[i])
                                      << "] [ver=" << applyVisitor(visitor, (*ver_col.column)[i]) << "]");
                }
                throw Exception(error_msg);
            }
        }

        // Write block to the output stream
        DMFileBlockOutputStream::BlockProperty property;
        std::tie(cur_effective_num_rows, cur_not_clean_rows, property.gc_hint_version) //
            = child->getMvccStatistics();
        property.effective_num_rows = cur_effective_num_rows - last_effective_num_rows;
        property.not_clean_rows     = cur_not_clean_rows - last_not_clean_rows;
        dt_stream->write(block, property);

        commit_rows += block.rows();
        last_effective_num_rows = cur_effective_num_rows;
        last_not_clean_rows     = cur_not_clean_rows;
    }
}

PageIds SSTFilesToDTFilesOutputStream::ingestIds() const
{
    PageIds ids;
    for (const auto & file : ingest_files)
    {
        ids.emplace_back(file->fileId());
    }
    return ids;
}

void SSTFilesToDTFilesOutputStream::cancel()
{
    // Try a lightweight cleanup the file generated by this stream (marking them able to be GC-ed).
    for (auto & file : ingest_files)
    {
        try
        {
            file->enableGC();
        }
        catch (...)
        {
            tryLogCurrentException(log, "ignore exception while canceling SST files to DeltaTree files stream [file=" + file->path() + "]");
        }
    }
}

} // namespace DM
} // namespace DB
